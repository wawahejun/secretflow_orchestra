#!/usr/bin/env python3
"""
Orchestraå®éªŒè¿è¡Œè„šæœ¬
æä¾›å‘½ä»¤è¡Œæ¥å£æ¥è¿è¡ŒCIFAR-10å’ŒCIFAR-100ä¸Šçš„Orchestraå®éªŒ
"""

import argparse

import sys
import json
from datetime import datetime
from typing import List, Dict
import os
# æ˜¾å¼è®¾ç½®åç«¯ï¼ˆæ ¹æ®ç¯å¢ƒé€‰æ‹©ï¼‰
if os.environ.get('MPLBACKEND') == 'module://matplotlib_inline.backend_inline':
    os.environ['MPLBACKEND'] = 'agg'  # æ›¿æ¢ä¸ºå…¼å®¹çš„åç«¯

import matplotlib.pyplot as plt

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from cifar_experiments import CIFAROrchestralExperiment, run_cifar_experiments
from federated_orchestra import OrchestraConfig

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='è¿è¡ŒOrchestraè”é‚¦å­¦ä¹ å®éªŒ',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # æ•°æ®é›†é€‰æ‹©
    parser.add_argument(
        '--datasets', 
        nargs='+', 
        choices=['cifar10', 'cifar100'], 
        default=['cifar10'],
        help='è¦è¿è¡Œå®éªŒçš„æ•°æ®é›†'
    )
    
    # è”é‚¦å­¦ä¹ å‚æ•°
    parser.add_argument(
        '--num-parties', 
        type=int, 
        default=3,
        help='è”é‚¦å­¦ä¹ å‚ä¸æ–¹æ•°é‡'
    )
    
    parser.add_argument(
        '--split-strategy', 
        choices=['iid', 'non_iid_dirichlet', 'non_iid_pathological'], 
        default='iid',
        help='æ•°æ®åˆ†å‰²ç­–ç•¥'
    )
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument(
        '--hidden-dims', 
        nargs='+', 
        type=int, 
        default=[1024, 512, 256],
        help='éšè—å±‚ç»´åº¦'
    )
    
    parser.add_argument(
        '--embedding-dim', 
        type=int, 
        default=128,
        help='åµŒå…¥ç»´åº¦'
    )
    
    parser.add_argument(
        '--dropout-rate', 
        type=float, 
        default=0.2,
        help='Dropoutç‡'
    )
    
    parser.add_argument(
        '--temperature', 
        type=float, 
        default=0.5,
        help='å¯¹æ¯”å­¦ä¹ æ¸©åº¦å‚æ•°'
    )
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument(
        '--learning-rate', 
        type=float, 
        default=0.001,
        help='å­¦ä¹ ç‡'
    )
    
    parser.add_argument(
        '--batch-size', 
        type=int, 
        default=256,
        help='æ‰¹æ¬¡å¤§å°'
    )
    
    parser.add_argument(
        '--num-epochs', 
        type=int, 
        default=50,
        help='è®­ç»ƒè½®æ•°'
    )
    
    parser.add_argument(
        '--communication-rounds', 
        type=int, 
        default=20,
        help='è”é‚¦é€šä¿¡è½®æ•°'
    )
    
    parser.add_argument(
        '--local-epochs', 
        type=int, 
        default=5,
        help='æœ¬åœ°è®­ç»ƒè½®æ•°'
    )
    
    # æŸå¤±æƒé‡
    parser.add_argument(
        '--contrastive-weight', 
        type=float, 
        default=1.0,
        help='å¯¹æ¯”å­¦ä¹ æŸå¤±æƒé‡'
    )
    
    parser.add_argument(
        '--clustering-weight', 
        type=float, 
        default=1.0,
        help='èšç±»æŸå¤±æƒé‡'
    )
    
    parser.add_argument(
        '--consistency-weight', 
        type=float, 
        default=0.5,
        help='ä¸€è‡´æ€§æŸå¤±æƒé‡'
    )
    
    # è¾“å‡ºè®¾ç½®
    parser.add_argument(
        '--output-dir', 
        type=str, 
        default='./orchestra_results',
        help='ç»“æœè¾“å‡ºç›®å½•'
    )
    
    parser.add_argument(
        '--experiment-name', 
        type=str, 
        default=None,
        help='å®éªŒåç§°ï¼ˆç”¨äºåŒºåˆ†ä¸åŒå®éªŒï¼‰'
    )
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument(
        '--seed', 
        type=int, 
        default=42,
        help='éšæœºç§å­'
    )
    
    parser.add_argument(
        '--device', 
        choices=['auto', 'cpu', 'cuda'], 
        default='auto',
        help='è®¡ç®—è®¾å¤‡'
    )
    
    parser.add_argument(
        '--verbose', 
        action='store_true',
        help='è¯¦ç»†è¾“å‡º'
    )
    
    parser.add_argument(
        '--save-models', 
        action='store_true',
        help='ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹'
    )
    
    parser.add_argument(
        '--skip-visualization', 
        action='store_true',
        help='è·³è¿‡ç»“æœå¯è§†åŒ–'
    )
    
    return parser.parse_args()

def setup_experiment_environment(args):
    """è®¾ç½®å®éªŒç¯å¢ƒ"""
    import torch
    import numpy as np
    import random
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)
    
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"éšæœºç§å­: {args.seed}")
    
    return device

def create_experiment_config(args, dataset: str) -> OrchestraConfig:
    """åˆ›å»ºå®éªŒé…ç½®"""
    # æ ¹æ®æ•°æ®é›†è®¾ç½®èšç±»æ•°
    num_clusters = 10 if dataset == 'cifar10' else 100
    
    config = OrchestraConfig(
        input_dim=3072,  # 32*32*3 for CIFAR
        hidden_dims=args.hidden_dims,
        embedding_dim=args.embedding_dim,
        num_clusters=num_clusters,
        dropout_rate=args.dropout_rate,
        temperature=args.temperature,
        learning_rate=args.learning_rate,
        batch_size=args.batch_size,
        num_epochs=args.num_epochs,
        communication_rounds=args.communication_rounds,
        local_epochs=args.local_epochs,
        contrastive_weight=args.contrastive_weight,
        clustering_weight=args.clustering_weight,
        consistency_weight=args.consistency_weight
    )
    
    return config

def run_single_experiment(dataset: str, args, device: str) -> Dict:
    """è¿è¡Œå•ä¸ªæ•°æ®é›†çš„å®éªŒ"""
    print(f"\n{'='*80}")
    print(f"å¼€å§‹ {dataset.upper()} å®éªŒ")
    print(f"{'='*80}")
    
    # åˆ›å»ºå®éªŒåç§°
    if args.experiment_name:
        exp_name = f"{args.experiment_name}_{dataset}"
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        exp_name = f"orchestra_{dataset}_{timestamp}"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.join(args.output_dir, exp_name)
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜å®éªŒé…ç½®
    config = create_experiment_config(args, dataset)
    config_path = os.path.join(output_dir, 'experiment_config.json')
    with open(config_path, 'w', encoding='utf-8') as f:
        config_dict = config.__dict__.copy()
        config_dict.update({
            'dataset': dataset,
            'num_parties': args.num_parties,
            'split_strategy': args.split_strategy,
            'seed': args.seed,
            'device': device,
            'experiment_name': exp_name,
            'timestamp': datetime.now().isoformat()
        })
        json.dump(config_dict, f, indent=2, ensure_ascii=False)
    
    print(f"å®éªŒé…ç½®å·²ä¿å­˜: {config_path}")
    
    # åˆ›å»ºå®éªŒå¯¹è±¡
    experiment = CIFAROrchestralExperiment(
        dataset_name=dataset,
        num_parties=args.num_parties,
        split_strategy=args.split_strategy,
        output_dir=output_dir
    )
    
    # è¿è¡Œå®éªŒ
    try:
        centralized_results, federated_results = experiment.run_complete_experiment(config)
        
        # ä¿å­˜é¢å¤–çš„å®éªŒå…ƒæ•°æ®
        metadata = {
            'experiment_name': exp_name,
            'dataset': dataset,
            'success': True,
            'completion_time': datetime.now().isoformat(),
            'config': config_dict
        }
        
        metadata_path = os.path.join(output_dir, 'experiment_metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        return {
            'success': True,
            'centralized': centralized_results,
            'federated': federated_results,
            'output_dir': output_dir,
            'experiment_name': exp_name
        }
        
    except Exception as e:
        print(f"å®éªŒå¤±è´¥: {e}")
        
        # ä¿å­˜é”™è¯¯ä¿¡æ¯
        error_metadata = {
            'experiment_name': exp_name,
            'dataset': dataset,
            'success': False,
            'error': str(e),
            'completion_time': datetime.now().isoformat(),
            'config': config_dict
        }
        
        error_path = os.path.join(output_dir, 'experiment_error.json')
        with open(error_path, 'w', encoding='utf-8') as f:
            json.dump(error_metadata, f, indent=2, ensure_ascii=False)
        
        return {
            'success': False,
            'error': str(e),
            'output_dir': output_dir,
            'experiment_name': exp_name
        }

def print_experiment_summary(results: Dict[str, Dict]):
    """æ‰“å°æ‰€æœ‰å®éªŒçš„æ€»ç»“"""
    print("\n" + "="*100)
    print("ORCHESTRA å®éªŒæ€»ç»“")
    print("="*100)
    
    successful_experiments = 0
    failed_experiments = 0
    
    for dataset, result in results.items():
        print(f"\n{dataset.upper()}:")
        if result['success']:
            successful_experiments += 1
            print(f"  âœ“ æˆåŠŸå®Œæˆ")
            print(f"  ğŸ“ è¾“å‡ºç›®å½•: {result['output_dir']}")
            
            # æ‰“å°å…³é”®æŒ‡æ ‡
            if 'centralized' in result and 'final_results' in result['centralized']:
                final_results = result['centralized']['final_results']
                print(f"  ğŸ“Š ARI Score: {final_results.get('adjusted_rand_score', 'N/A'):.4f}")
                print(f"  ğŸ“Š NMI Score: {final_results.get('normalized_mutual_info', 'N/A'):.4f}")
                print(f"  ğŸ“Š Silhouette Score: {final_results.get('silhouette_score', 'N/A'):.4f}")
        else:
            failed_experiments += 1
            print(f"  âœ— å¤±è´¥")
            print(f"  âŒ é”™è¯¯: {result['error']}")
            print(f"  ğŸ“ é”™è¯¯æ—¥å¿—: {result['output_dir']}")
    
    print(f"\næ€»è®¡:")
    print(f"  æˆåŠŸ: {successful_experiments}")
    print(f"  å¤±è´¥: {failed_experiments}")
    print(f"  æ€»è®¡: {successful_experiments + failed_experiments}")
    
    if successful_experiments > 0:
        print(f"\nğŸ‰ å®éªŒå®Œæˆï¼æŸ¥çœ‹ç»“æœç›®å½•è·å–è¯¦ç»†ä¿¡æ¯ã€‚")
    
    print("="*100)

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_arguments()
    
    # æ‰“å°å®éªŒä¿¡æ¯
    print("Orchestra è”é‚¦å­¦ä¹ å®éªŒ")
    print(f"æ•°æ®é›†: {', '.join(args.datasets)}")
    print(f"å‚ä¸æ–¹æ•°é‡: {args.num_parties}")
    print(f"åˆ†å‰²ç­–ç•¥: {args.split_strategy}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # è®¾ç½®ç¯å¢ƒ
    device = setup_experiment_environment(args)
    
    # åˆ›å»ºä¸»è¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è¿è¡Œå®éªŒ
    results = {}
    
    for dataset in args.datasets:
        result = run_single_experiment(dataset, args, device)
        results[dataset] = result
    
    # æ‰“å°æ€»ç»“
    print_experiment_summary(results)
    
    # ä¿å­˜æ€»ä½“ç»“æœ
    summary_path = os.path.join(args.output_dir, 'experiment_summary.json')
    summary_data = {
        'timestamp': datetime.now().isoformat(),
        'arguments': vars(args),
        'device': device,
        'results': {k: {key: v[key] for key in ['success', 'experiment_name', 'output_dir'] if key in v} 
                   for k, v in results.items()}
    }
    
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nå®éªŒæ€»ç»“å·²ä¿å­˜: {summary_path}")
    
    return results

if __name__ == "__main__":
    try:
        results = main()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„å®éªŒ
        failed_count = sum(1 for r in results.values() if not r['success'])
        if failed_count > 0:
            sys.exit(1)  # æœ‰å¤±è´¥çš„å®éªŒæ—¶è¿”å›é”™è¯¯ç 
        else:
            sys.exit(0)  # æ‰€æœ‰å®éªŒæˆåŠŸ
            
    except KeyboardInterrupt:
        print("\nå®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nå®éªŒè¿è¡Œå‡ºé”™: {e}")
        sys.exit(1)