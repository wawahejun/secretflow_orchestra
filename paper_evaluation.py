#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸè®ºæ–‡æ ‡å‡†è¯„ä»·æŒ‡æ ‡å®ç°
åŒ…å«çº¿æ€§æ¢æµ‹ã€1%æ ‡ç­¾åŠç›‘ç£å­¦ä¹ ã€10%æ ‡ç­¾åŠç›‘ç£å­¦ä¹ 
åŸºäºè®ºæ–‡: Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering
"""

import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset, Subset
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, adjusted_rand_score, normalized_mutual_info_score
from typing import Dict, List, Tuple, Optional, Any
import json
import logging
from collections import defaultdict

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LinearProbeEvaluator:
    """çº¿æ€§æ¢æµ‹è¯„ä¼°å™¨ - åŸè®ºæ–‡æ ‡å‡†"""
    
    def __init__(self, 
                 input_dim: int,
                 num_classes: int = 10,
                 max_iter: int = 1000,
                 random_state: int = 42):
        self.input_dim = input_dim
        self.num_classes = num_classes
        self.max_iter = max_iter
        self.random_state = random_state
        self.classifier = None
        
    def extract_features(self, model: nn.Module, data_loader: DataLoader, device: torch.device) -> Tuple[np.ndarray, np.ndarray]:
        """æå–ç‰¹å¾è¡¨ç¤º"""
        model.eval()
        features = []
        labels = []
        
        with torch.no_grad():
            for batch_idx, batch_data in enumerate(data_loader):
                # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
                if isinstance(batch_data, (list, tuple)):
                    if len(batch_data) == 2:
                        data, target = batch_data
                    else:
                        data = batch_data[0]
                        target = batch_data[1] if len(batch_data) > 1 else torch.zeros(data.shape[0])
                else:
                    data = batch_data
                    target = torch.zeros(data.shape[0])
                
                # å¤„ç†å¤šè§†å›¾æ•°æ®
                if isinstance(data, (list, tuple)):
                    data = data[0]  # å–ç¬¬ä¸€ä¸ªè§†å›¾
                if isinstance(target, (list, tuple)):
                    target = target[0]
                
                data = data.to(device)
                
                # è·å–ç‰¹å¾è¡¨ç¤º
                try:
                    if hasattr(model, 'get_representations'):
                        feat, _ = model.get_representations(data)
                    elif hasattr(model, 'backbone'):
                        feat = model.backbone(data)
                    elif hasattr(model, 'forward') and hasattr(model, 'fc'):
                        # å¯¹äºæœ‰åˆ†ç±»å±‚çš„æ¨¡å‹ï¼Œè·å–åˆ†ç±»å±‚ä¹‹å‰çš„ç‰¹å¾
                        x = data
                        for name, module in model.named_children():
                            if name != 'fc' and name != 'classifier':
                                x = module(x)
                        feat = x.view(x.size(0), -1)  # å±•å¹³
                    else:
                        feat = model(data, return_features=True) if 'return_features' in model.forward.__code__.co_varnames else model(data)
                    
                    # ç¡®ä¿ç‰¹å¾æ˜¯2Dçš„
                    if feat.dim() > 2:
                        feat = feat.view(feat.size(0), -1)
                    
                    features.append(feat.cpu().numpy())
                    labels.append(target.cpu().numpy() if torch.is_tensor(target) else target)
                    
                except Exception as e:
                    logger.warning(f"ç‰¹å¾æå–å¤±è´¥ (batch {batch_idx}): {e}")
                    continue
        
        if not features:
            raise ValueError("æœªèƒ½æå–åˆ°ä»»ä½•ç‰¹å¾")
        
        features = np.concatenate(features, axis=0)
        labels = np.concatenate(labels, axis=0)
        
        logger.info(f"æå–ç‰¹å¾å®Œæˆ: {features.shape}, æ ‡ç­¾: {labels.shape}")
        return features, labels
    
    def linear_probe_evaluation(self, 
                               train_features: np.ndarray, 
                               train_labels: np.ndarray,
                               test_features: np.ndarray, 
                               test_labels: np.ndarray) -> float:
        """çº¿æ€§æ¢æµ‹è¯„ä¼°"""
        # è®­ç»ƒçº¿æ€§åˆ†ç±»å™¨
        self.classifier = LogisticRegression(
            max_iter=self.max_iter,
            random_state=self.random_state,
            multi_class='ovr',
            solver='lbfgs'
        )
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        train_mean = np.mean(train_features, axis=0)
        train_std = np.std(train_features, axis=0) + 1e-8
        
        train_features_norm = (train_features - train_mean) / train_std
        test_features_norm = (test_features - train_mean) / train_std
        
        # è®­ç»ƒåˆ†ç±»å™¨
        self.classifier.fit(train_features_norm, train_labels)
        
        # é¢„æµ‹
        predictions = self.classifier.predict(test_features_norm)
        accuracy = accuracy_score(test_labels, predictions)
        
        return accuracy


class SemiSupervisedEvaluator:
    """åŠç›‘ç£å­¦ä¹ è¯„ä¼°å™¨ - åŸè®ºæ–‡æ ‡å‡†"""
    
    def __init__(self, 
                 input_dim: int,
                 num_classes: int = 10,
                 hidden_dim: int = 512,
                 learning_rate: float = 0.001,
                 epochs: int = 100,
                 batch_size: int = 64,
                 device: torch.device = None):
        self.input_dim = input_dim
        self.num_classes = num_classes
        self.hidden_dim = hidden_dim
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batch_size = batch_size
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def create_labeled_subset(self, 
                             features: np.ndarray, 
                             labels: np.ndarray, 
                             label_ratio: float) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """åˆ›å»ºæ ‡è®°å­é›†"""
        num_samples = len(features)
        num_labeled = int(num_samples * label_ratio)
        
        # ç¡®ä¿æ¯ä¸ªç±»åˆ«è‡³å°‘æœ‰ä¸€ä¸ªæ ·æœ¬
        unique_labels = np.unique(labels)
        samples_per_class = max(1, num_labeled // len(unique_labels))
        
        labeled_indices = []
        for label in unique_labels:
            class_indices = np.where(labels == label)[0]
            if len(class_indices) > 0:
                selected = np.random.choice(class_indices, 
                                          min(samples_per_class, len(class_indices)), 
                                          replace=False)
                labeled_indices.extend(selected)
        
        # å¦‚æœè¿˜éœ€è¦æ›´å¤šæ ·æœ¬ï¼Œéšæœºé€‰æ‹©
        if len(labeled_indices) < num_labeled:
            remaining_indices = np.setdiff1d(np.arange(num_samples), labeled_indices)
            additional = np.random.choice(remaining_indices, 
                                        num_labeled - len(labeled_indices), 
                                        replace=False)
            labeled_indices.extend(additional)
        
        labeled_indices = np.array(labeled_indices[:num_labeled])
        unlabeled_indices = np.setdiff1d(np.arange(num_samples), labeled_indices)
        
        return (features[labeled_indices], labels[labeled_indices],
                features[unlabeled_indices], labels[unlabeled_indices])
    
    def create_mlp_classifier(self) -> nn.Module:
        """åˆ›å»ºMLPåˆ†ç±»å™¨"""
        return nn.Sequential(
            nn.Linear(self.input_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(self.hidden_dim, self.hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(self.hidden_dim // 2, self.num_classes)
        )
    
    def train_semisupervised(self, 
                           labeled_features: np.ndarray,
                           labeled_labels: np.ndarray,
                           unlabeled_features: np.ndarray,
                           test_features: np.ndarray,
                           test_labels: np.ndarray) -> float:
        """åŠç›‘ç£è®­ç»ƒ"""
        # åˆ›å»ºåˆ†ç±»å™¨
        classifier = self.create_mlp_classifier().to(self.device)
        optimizer = torch.optim.Adam(classifier.parameters(), lr=self.learning_rate)
        criterion = nn.CrossEntropyLoss()
        
        # æ ‡å‡†åŒ–ç‰¹å¾ï¼ˆå…ˆåœ¨numpyä¸­è¿›è¡Œï¼‰
        all_features = np.concatenate([labeled_features, unlabeled_features], axis=0)
        mean = np.mean(all_features, axis=0)
        std = np.std(all_features, axis=0) + 1e-8
        
        # æ ‡å‡†åŒ–numpyæ•°ç»„
        labeled_features_norm = (labeled_features - mean) / std
        unlabeled_features_norm = (unlabeled_features - mean) / std
        test_features_norm = (test_features - mean) / std
        
        # è½¬æ¢ä¸ºå¼ é‡ï¼ˆç¡®ä¿æ¢¯åº¦è®¡ç®—ï¼‰
        labeled_features_tensor = torch.FloatTensor(labeled_features_norm).to(self.device).requires_grad_(False)
        labeled_labels_tensor = torch.LongTensor(labeled_labels).to(self.device)
        unlabeled_features_tensor = torch.FloatTensor(unlabeled_features_norm).to(self.device).requires_grad_(False)
        test_features_tensor = torch.FloatTensor(test_features_norm).to(self.device).requires_grad_(False)
        test_labels_tensor = torch.LongTensor(test_labels).to(self.device)
        
        best_accuracy = 0.0
        
        for epoch in range(self.epochs):
            classifier.train()
            
            # ç›‘ç£å­¦ä¹ æŸå¤±
            optimizer.zero_grad()
            labeled_outputs = classifier(labeled_features_tensor)
            supervised_loss = criterion(labeled_outputs, labeled_labels_tensor)
            
            # ç®€å•çš„åŠç›‘ç£ç­–ç•¥ï¼šä¼ªæ ‡ç­¾
            if epoch > 10:  # åœ¨å‡ ä¸ªepochåå¼€å§‹ä½¿ç”¨ä¼ªæ ‡ç­¾
                classifier.eval()
                with torch.no_grad():
                    unlabeled_outputs = classifier(unlabeled_features_tensor)
                    pseudo_labels = torch.argmax(unlabeled_outputs, dim=1)
                    confidence = torch.max(F.softmax(unlabeled_outputs, dim=1), dim=1)[0]
                    
                    # åªä½¿ç”¨é«˜ç½®ä¿¡åº¦çš„ä¼ªæ ‡ç­¾
                    high_conf_mask = confidence > 0.8
                
                classifier.train()
                if high_conf_mask.sum() > 0:
                    # é‡æ–°è®¡ç®—é«˜ç½®ä¿¡åº¦æ ·æœ¬çš„è¾“å‡ºï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
                    high_conf_features = unlabeled_features_tensor[high_conf_mask].detach()
                    pseudo_outputs = classifier(high_conf_features)
                    pseudo_loss = criterion(pseudo_outputs, pseudo_labels[high_conf_mask].detach())
                    total_loss = supervised_loss + 0.1 * pseudo_loss
                else:
                    total_loss = supervised_loss
            else:
                total_loss = supervised_loss
            
            total_loss.backward()
            optimizer.step()
            
            # è¯„ä¼°
            if (epoch + 1) % 10 == 0:
                classifier.eval()
                with torch.no_grad():
                    test_outputs = classifier(test_features_tensor)
                    predictions = torch.argmax(test_outputs, dim=1)
                    accuracy = (predictions == test_labels_tensor).float().mean().item()
                    
                    if accuracy > best_accuracy:
                        best_accuracy = accuracy
                    
                    logger.info(f"Epoch {epoch+1}/{self.epochs}, Loss: {total_loss.item():.4f}, Accuracy: {accuracy:.4f}")
        
        return best_accuracy


class PaperStandardEvaluator:
    """åŸè®ºæ–‡æ ‡å‡†è¯„ä¼°å™¨"""
    
    def __init__(self, 
                 num_classes: int = 10,
                 device: torch.device = None,
                 output_dir: str = './paper_evaluation_results'):
        self.num_classes = num_classes
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.output_dir = output_dir
        
        os.makedirs(output_dir, exist_ok=True)
        
        logger.info(f"åˆå§‹åŒ–åŸè®ºæ–‡æ ‡å‡†è¯„ä¼°å™¨ï¼Œè®¾å¤‡: {self.device}")
    
    def full_evaluation(self, 
                       model: nn.Module,
                       train_loader: DataLoader,
                       test_loader: DataLoader) -> Dict[str, Any]:
        """å®Œæ•´çš„åŸè®ºæ–‡æ ‡å‡†è¯„ä¼°"""
        
        logger.info("å¼€å§‹åŸè®ºæ–‡æ ‡å‡†è¯„ä¼°")
        
        # æå–ç‰¹å¾
        logger.info("æå–è®­ç»ƒé›†ç‰¹å¾...")
        probe_evaluator = LinearProbeEvaluator(input_dim=0, num_classes=self.num_classes)
        train_features, train_labels = probe_evaluator.extract_features(model, train_loader, self.device)
        
        logger.info("æå–æµ‹è¯•é›†ç‰¹å¾...")
        test_features, test_labels = probe_evaluator.extract_features(model, test_loader, self.device)
        
        # æ›´æ–°input_dim
        input_dim = train_features.shape[1]
        probe_evaluator.input_dim = input_dim
        
        results = {}
        
        # 1. çº¿æ€§æ¢æµ‹è¯„ä¼°
        logger.info("æ‰§è¡Œçº¿æ€§æ¢æµ‹è¯„ä¼°...")
        linear_probe_acc = probe_evaluator.linear_probe_evaluation(
            train_features, train_labels, test_features, test_labels
        )
        results['linear_probe_accuracy'] = linear_probe_acc
        logger.info(f"çº¿æ€§æ¢æµ‹å‡†ç¡®ç‡: {linear_probe_acc:.4f} ({linear_probe_acc*100:.2f}%)")
        
        # 2. 1% æ ‡ç­¾åŠç›‘ç£å­¦ä¹ 
        logger.info("æ‰§è¡Œ1%æ ‡ç­¾åŠç›‘ç£å­¦ä¹ è¯„ä¼°...")
        semisup_evaluator = SemiSupervisedEvaluator(
            input_dim=input_dim,
            num_classes=self.num_classes,
            device=self.device,
            epochs=50  # å‡å°‘epochæ•°ä»¥åŠ å¿«è¯„ä¼°
        )
        
        # ä½¿ç”¨è®­ç»ƒé›†çš„1%ä½œä¸ºæ ‡è®°æ•°æ®
        labeled_1_features, labeled_1_labels, unlabeled_1_features, _ = semisup_evaluator.create_labeled_subset(
            train_features, train_labels, label_ratio=0.01
        )
        
        semisup_1_acc = semisup_evaluator.train_semisupervised(
            labeled_1_features, labeled_1_labels, unlabeled_1_features,
            test_features, test_labels
        )
        results['semisupervised_1_percent'] = semisup_1_acc
        logger.info(f"1%æ ‡ç­¾åŠç›‘ç£å‡†ç¡®ç‡: {semisup_1_acc:.4f} ({semisup_1_acc*100:.2f}%)")
        
        # 3. 10% æ ‡ç­¾åŠç›‘ç£å­¦ä¹ 
        logger.info("æ‰§è¡Œ10%æ ‡ç­¾åŠç›‘ç£å­¦ä¹ è¯„ä¼°...")
        labeled_10_features, labeled_10_labels, unlabeled_10_features, _ = semisup_evaluator.create_labeled_subset(
            train_features, train_labels, label_ratio=0.10
        )
        
        semisup_10_acc = semisup_evaluator.train_semisupervised(
            labeled_10_features, labeled_10_labels, unlabeled_10_features,
            test_features, test_labels
        )
        results['semisupervised_10_percent'] = semisup_10_acc
        logger.info(f"10%æ ‡ç­¾åŠç›‘ç£å‡†ç¡®ç‡: {semisup_10_acc:.4f} ({semisup_10_acc*100:.2f}%)")
        
        # 4. èšç±»è¯„ä¼°ï¼ˆé¢å¤–æŒ‡æ ‡ï¼‰
        logger.info("æ‰§è¡Œèšç±»è¯„ä¼°...")
        kmeans = KMeans(n_clusters=self.num_classes, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(test_features)
        
        ari = adjusted_rand_score(test_labels, cluster_labels)
        nmi = normalized_mutual_info_score(test_labels, cluster_labels)
        
        results['clustering_ari'] = ari
        results['clustering_nmi'] = nmi
        logger.info(f"èšç±»ARI: {ari:.4f}, NMI: {nmi:.4f}")
        
        # ä¿å­˜ç»“æœ
        self.save_results(results)
        
        # æ‰“å°æ±‡æ€»
        self.print_summary(results)
        
        return results
    
    def save_results(self, results: Dict[str, Any]):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        results_file = os.path.join(self.output_dir, 'paper_standard_results.json')
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_results = {}
        for key, value in results.items():
            if isinstance(value, (np.ndarray, torch.Tensor)):
                serializable_results[key] = float(value)
            else:
                serializable_results[key] = value
        
        with open(results_file, 'w') as f:
            json.dump(serializable_results, f, indent=2)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    def print_summary(self, results: Dict[str, Any]):
        """æ‰“å°è¯„ä¼°ç»“æœæ±‡æ€»"""
        print("\n" + "=" * 60)
        print("åŸè®ºæ–‡æ ‡å‡†è¯„ä¼°ç»“æœæ±‡æ€»")
        print("=" * 60)
        
        print(f"\nğŸ“Š ä¸»è¦è¯„ä¼°æŒ‡æ ‡:")
        print(f"  â€¢ çº¿æ€§æ¢æµ‹å‡†ç¡®ç‡:     {results['linear_probe_accuracy']:.4f} ({results['linear_probe_accuracy']*100:.2f}%)")
        print(f"  â€¢ 1%æ ‡ç­¾åŠç›‘ç£å‡†ç¡®ç‡:  {results['semisupervised_1_percent']:.4f} ({results['semisupervised_1_percent']*100:.2f}%)")
        print(f"  â€¢ 10%æ ‡ç­¾åŠç›‘ç£å‡†ç¡®ç‡: {results['semisupervised_10_percent']:.4f} ({results['semisupervised_10_percent']*100:.2f}%)")
        
        print(f"\nğŸ¯ èšç±»æ€§èƒ½:")
        print(f"  â€¢ è°ƒæ•´å…°å¾·æŒ‡æ•° (ARI): {results['clustering_ari']:.4f}")
        print(f"  â€¢ æ ‡å‡†åŒ–äº’ä¿¡æ¯ (NMI): {results['clustering_nmi']:.4f}")
        
        print(f"\nğŸ“ˆ ä¸åŸè®ºæ–‡å¯¹æ¯” (CIFAR-10, Î±=0.1, 100å®¢æˆ·ç«¯):")
        print(f"  â€¢ åŸè®ºæ–‡çº¿æ€§æ¢æµ‹:     71.58%")
        print(f"  â€¢ åŸè®ºæ–‡1%åŠç›‘ç£:     60.33%")
        print(f"  â€¢ åŸè®ºæ–‡10%åŠç›‘ç£:    66.20%")
        print(f"  â€¢ å½“å‰çº¿æ€§æ¢æµ‹:       {results['linear_probe_accuracy']*100:.2f}%")
        print(f"  â€¢ å½“å‰1%åŠç›‘ç£:       {results['semisupervised_1_percent']*100:.2f}%")
        print(f"  â€¢ å½“å‰10%åŠç›‘ç£:      {results['semisupervised_10_percent']*100:.2f}%")
        
        # è®¡ç®—æ€§èƒ½æ¯”ä¾‹
        linear_ratio = results['linear_probe_accuracy'] / 0.7158
        semisup_1_ratio = results['semisupervised_1_percent'] / 0.6033
        semisup_10_ratio = results['semisupervised_10_percent'] / 0.6620
        
        print(f"\nğŸ“Š æ€§èƒ½æ¯”ä¾‹ (å½“å‰/åŸè®ºæ–‡):")
        print(f"  â€¢ çº¿æ€§æ¢æµ‹:   {linear_ratio:.2f}x")
        print(f"  â€¢ 1%åŠç›‘ç£:   {semisup_1_ratio:.2f}x")
        print(f"  â€¢ 10%åŠç›‘ç£:  {semisup_10_ratio:.2f}x")
        
        print("=" * 60)


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    import torch
    from torch.utils.data import TensorDataset, DataLoader
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    num_train = 1000
    num_test = 200
    num_features = 512
    num_classes = 10
    
    # æ¨¡æ‹Ÿç‰¹å¾å’Œæ ‡ç­¾
    train_features = torch.randn(num_train, num_features)
    train_labels = torch.randint(0, num_classes, (num_train,))
    test_features = torch.randn(num_test, num_features)
    test_labels = torch.randint(0, num_classes, (num_test,))
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = TensorDataset(train_features, train_labels)
    test_dataset = TensorDataset(test_features, test_labels)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
    class MockModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.fc = nn.Linear(num_features, num_features)
        
        def forward(self, x, return_features=False):
            if return_features:
                return self.fc(x)
            return self.fc(x)
    
    model = MockModel()
    
    # æµ‹è¯•è¯„ä¼°å™¨
    evaluator = PaperStandardEvaluator(num_classes=num_classes)
    results = evaluator.full_evaluation(model, train_loader, test_loader)