#!/usr/bin/env python3
"""
Orchestraå®ç°æµ‹è¯•è„šæœ¬
éªŒè¯æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œè®­ç»ƒå™¨çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
import torch
import numpy as np
from typing import Dict, Any
import unittest
import tempfile
import shutil

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from orchestra_model import (
    ContrastiveEncoder, 
    ClusteringHead, 
    OrchestraModel, 
    OrchestraLoss, 
    OrchestraTrainer
)
from federated_orchestra import (
    OrchestraConfig,
    FederatedOrchestraModel,
    OrchestraDataProcessor
)

class TestOrchestraComponents(unittest.TestCase):
    """Orchestraç»„ä»¶æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•è®¾ç½®"""
        self.device = torch.device('cpu')  # ä½¿ç”¨CPUè¿›è¡Œæµ‹è¯•
        self.batch_size = 32
        self.input_dim = 100
        self.embedding_dim = 64
        self.num_clusters = 10
        self.hidden_dims = [256, 128]
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_data = torch.randn(self.batch_size, self.input_dim)
        self.test_labels = torch.randint(0, self.num_clusters, (self.batch_size,))
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp()
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def test_contrastive_encoder(self):
        """æµ‹è¯•å¯¹æ¯”å­¦ä¹ ç¼–ç å™¨"""
        print("\næµ‹è¯•å¯¹æ¯”å­¦ä¹ ç¼–ç å™¨...")
        
        encoder = ContrastiveEncoder(
            input_dim=self.input_dim,
            hidden_dims=self.hidden_dims,
            output_dim=self.embedding_dim,
            dropout_rate=0.2
        )
        
        # å‰å‘ä¼ æ’­æµ‹è¯•
        embeddings = encoder(self.test_data)
        
        # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
        expected_shape = (self.batch_size, self.embedding_dim)
        self.assertEqual(embeddings.shape, expected_shape, 
                        f"ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {embeddings.shape}")
        
        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸ºæœ‰é™å€¼
        self.assertTrue(torch.isfinite(embeddings).all(), "ç¼–ç å™¨è¾“å‡ºåŒ…å«éæœ‰é™å€¼")
        
        print(f"âœ“ ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶: {embeddings.shape}")
        print(f"âœ“ ç¼–ç å™¨è¾“å‡ºèŒƒå›´: [{embeddings.min():.4f}, {embeddings.max():.4f}]")
    
    def test_clustering_head(self):
        """æµ‹è¯•èšç±»å¤´"""
        print("\næµ‹è¯•èšç±»å¤´...")
        
        clustering_head = ClusteringHead(
            input_dim=self.embedding_dim,
            num_clusters=self.num_clusters,
            temperature=0.5
        )
        
        # åˆ›å»ºæµ‹è¯•åµŒå…¥
        embeddings = torch.randn(self.batch_size, self.embedding_dim)
        
        # å‰å‘ä¼ æ’­æµ‹è¯•
        cluster_probs = clustering_head(embeddings)
        
        # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
        expected_probs_shape = (self.batch_size, self.num_clusters)
        
        self.assertEqual(cluster_probs.shape, expected_probs_shape,
                        f"èšç±»æ¦‚ç‡å½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_probs_shape}, å®é™… {cluster_probs.shape}")
        
        # æ£€æŸ¥æ¦‚ç‡å’Œä¸º1
        prob_sums = cluster_probs.sum(dim=1)
        self.assertTrue(torch.allclose(prob_sums, torch.ones_like(prob_sums), atol=1e-6),
                       "èšç±»æ¦‚ç‡å’Œä¸ä¸º1")
        
        # æ£€æŸ¥æ¦‚ç‡èŒƒå›´
        self.assertTrue((cluster_probs >= 0).all() and (cluster_probs <= 1).all(),
                       "èšç±»æ¦‚ç‡è¶…å‡º[0,1]èŒƒå›´")
        
        print(f"âœ“ èšç±»æ¦‚ç‡å½¢çŠ¶: {cluster_probs.shape}")
        print(f"âœ“ æ¦‚ç‡å’ŒèŒƒå›´: [{prob_sums.min():.6f}, {prob_sums.max():.6f}]")
    
    def test_orchestra_model(self):
        """æµ‹è¯•å®Œæ•´Orchestraæ¨¡å‹"""
        print("\næµ‹è¯•å®Œæ•´Orchestraæ¨¡å‹...")
        
        model = OrchestraModel(
            input_dim=self.input_dim,
            hidden_dims=self.hidden_dims,
            embedding_dim=self.embedding_dim,
            num_clusters=self.num_clusters,
            dropout_rate=0.2,
            temperature=0.5
        )
        
        # å‰å‘ä¼ æ’­æµ‹è¯•
        outputs = model(self.test_data)
        
        # è§£åŒ…è¾“å‡º
        embeddings, cluster_probs, projections = outputs
        
        # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
        self.assertEqual(embeddings.shape, (self.batch_size, self.embedding_dim))
        self.assertEqual(cluster_probs.shape, (self.batch_size, self.num_clusters))
        self.assertIsNone(projections)  # é»˜è®¤ä¸è¿”å›æŠ•å½±
        
        print(f"âœ“ åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
        print(f"âœ“ èšç±»æ¦‚ç‡å½¢çŠ¶: {cluster_probs.shape}")
        print(f"âœ“ æŠ•å½±: {projections}")
    
    def test_orchestra_loss(self):
        """æµ‹è¯•OrchestraæŸå¤±å‡½æ•°"""
        print("\næµ‹è¯•OrchestraæŸå¤±å‡½æ•°...")
        
        loss_fn = OrchestraLoss(
            contrastive_weight=1.0,
            clustering_weight=1.0,
            consistency_weight=0.5,
            temperature=0.5
        )
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        data_batches = [self.test_data[:16], self.test_data[16:]]
        
        # åˆ›å»ºæ¨¡å‹è¾“å‡º
        model = OrchestraModel(
            input_dim=self.input_dim,
            hidden_dims=self.hidden_dims,
            embedding_dim=self.embedding_dim,
            num_clusters=self.num_clusters
        )
        
        outputs_list = [model(batch) for batch in data_batches]
        
        # æå–projectionså’Œcluster_probs
        projections_list = []
        cluster_probs_list = []
        
        for outputs in outputs_list:
            embeddings, cluster_probs, projections = outputs
            # å¦‚æœæ²¡æœ‰projectionsï¼Œä½¿ç”¨embeddingsä½œä¸ºprojections
            if projections is None:
                projections = embeddings
            projections_list.append(projections)
            cluster_probs_list.append(cluster_probs)
        
        # è®¡ç®—æŸå¤±
        losses = loss_fn(projections_list, cluster_probs_list)
        
        # æ£€æŸ¥æŸå¤±é”®
        expected_keys = {'total', 'contrastive', 'clustering', 'consistency'}
        self.assertEqual(set(losses.keys()), expected_keys,
                        f"æŸå¤±é”®é”™è¯¯: æœŸæœ› {expected_keys}, å®é™… {set(losses.keys())}")
        
        # æ£€æŸ¥æŸå¤±å€¼
        for key, value in losses.items():
            self.assertIsInstance(value, torch.Tensor, f"{key}æŸå¤±ä¸æ˜¯tensor")
            self.assertEqual(value.dim(), 0, f"{key}æŸå¤±ä¸æ˜¯æ ‡é‡")
            self.assertTrue(torch.isfinite(value), f"{key}æŸå¤±ä¸æ˜¯æœ‰é™å€¼")
            if key != 'total':  # totalå¯èƒ½ä¸ºè´Ÿï¼ˆç”±äºconsistency lossï¼‰
                self.assertTrue(value >= 0, f"{key}æŸå¤±ä¸ºè´Ÿå€¼: {value}")
        
        print(f"âœ“ æŸå¤±ç»„ä»¶: {list(losses.keys())}")
        for key, value in losses.items():
            print(f"âœ“ {key}æŸå¤±: {value.item():.6f}")
    
    def test_orchestra_trainer(self):
        """æµ‹è¯•Orchestraè®­ç»ƒå™¨"""
        print("\næµ‹è¯•Orchestraè®­ç»ƒå™¨...")
        
        # åˆ›å»ºæ¨¡å‹å’ŒæŸå¤±å‡½æ•°
        model = OrchestraModel(
            input_dim=self.input_dim,
            hidden_dims=self.hidden_dims,
            embedding_dim=self.embedding_dim,
            num_clusters=self.num_clusters
        )
        
        loss_fn = OrchestraLoss(
            contrastive_weight=1.0,
            clustering_weight=1.0,
            consistency_weight=0.5
        )
        
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
        trainer = OrchestraTrainer(model, loss_fn, optimizer, self.device)
        
        # æµ‹è¯•è®­ç»ƒæ­¥éª¤
        data_batches = [self.test_data[:16], self.test_data[16:]]
        
        # è®°å½•åˆå§‹æŸå¤±
        initial_losses = trainer.train_step(data_batches)
        
        # å†æ¬¡è®­ç»ƒ
        second_losses = trainer.train_step(data_batches)
        
        # æ£€æŸ¥æŸå¤±ç»“æ„
        expected_keys = {'total', 'contrastive', 'clustering', 'consistency'}
        self.assertEqual(set(initial_losses.keys()), expected_keys)
        self.assertEqual(set(second_losses.keys()), expected_keys)
        
        print(f"âœ“ åˆå§‹æŸå¤±: {initial_losses['total']:.6f}")
        print(f"âœ“ ç¬¬äºŒæ¬¡æŸå¤±: {second_losses['total']:.6f}")
        
        # æµ‹è¯•è¯„ä¼°
        eval_results = trainer.evaluate(self.test_data, self.test_labels)
        
        # æ£€æŸ¥è¯„ä¼°ç»“æœ
        expected_eval_keys = {
            'adjusted_rand_score', 'normalized_mutual_info', 
            'silhouette_score', 'num_clusters_used', 'cluster_entropy'
        }
        self.assertTrue(expected_eval_keys.issubset(set(eval_results.keys())),
                      f"è¯„ä¼°ç»“æœç¼ºå°‘å¿…è¦é”®: {expected_eval_keys - set(eval_results.keys())}")
        
        print(f"âœ“ è¯„ä¼°æŒ‡æ ‡: {list(eval_results.keys())}")
        for key, value in eval_results.items():
            if isinstance(value, (int, float)):
                print(f"âœ“ {key}: {value:.4f}")
    
    def test_data_processor(self):
        """æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
        print("\næµ‹è¯•æ•°æ®å¤„ç†å™¨...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        num_samples = 1000
        data = np.random.randn(num_samples, self.input_dim)
        labels = np.random.randint(0, self.num_clusters, num_samples)
        
        # æµ‹è¯•è”é‚¦æ•°æ®åˆ†å‰²
        num_parties = 3
        federated_data = OrchestraDataProcessor.create_federated_split(
            data=data,
            labels=labels,
            num_parties=num_parties,
            split_strategy='iid'
        )
        
        # æ£€æŸ¥åˆ†å‰²ç»“æœ
        self.assertEqual(len(federated_data), num_parties,
                        f"å‚ä¸æ–¹æ•°é‡é”™è¯¯: æœŸæœ› {num_parties}, å®é™… {len(federated_data)}")
        
        total_samples = 0
        for party, (party_data, party_labels) in federated_data.items():
            self.assertIsInstance(party_data, np.ndarray, f"{party}æ•°æ®ä¸æ˜¯numpyæ•°ç»„")
            self.assertIsInstance(party_labels, np.ndarray, f"{party}æ ‡ç­¾ä¸æ˜¯numpyæ•°ç»„")
            self.assertEqual(party_data.shape[0], party_labels.shape[0],
                           f"{party}æ•°æ®å’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…")
            self.assertEqual(party_data.shape[1], self.input_dim,
                           f"{party}æ•°æ®ç»´åº¦é”™è¯¯")
            total_samples += len(party_data)
        
        self.assertEqual(total_samples, num_samples,
                        f"æ€»æ ·æœ¬æ•°ä¸åŒ¹é…: æœŸæœ› {num_samples}, å®é™… {total_samples}")
        
        print(f"âœ“ è”é‚¦æ•°æ®åˆ†å‰²æˆåŠŸ")
        print(f"âœ“ å‚ä¸æ–¹æ•°é‡: {len(federated_data)}")
        for party, (party_data, party_labels) in federated_data.items():
            print(f"âœ“ {party}: {len(party_data)} æ ·æœ¬")
    
    def test_orchestra_config(self):
        """æµ‹è¯•Orchestraé…ç½®"""
        print("\næµ‹è¯•Orchestraé…ç½®...")
        
        config = OrchestraConfig(
            input_dim=self.input_dim,
            hidden_dims=self.hidden_dims,
            embedding_dim=self.embedding_dim,
            num_clusters=self.num_clusters
        )
        
        # æ£€æŸ¥é…ç½®å±æ€§
        self.assertEqual(config.input_dim, self.input_dim)
        self.assertEqual(config.hidden_dims, self.hidden_dims)
        self.assertEqual(config.embedding_dim, self.embedding_dim)
        self.assertEqual(config.num_clusters, self.num_clusters)
        
        # æ£€æŸ¥é»˜è®¤å€¼
        self.assertIsInstance(config.dropout_rate, float)
        self.assertIsInstance(config.temperature, float)
        self.assertIsInstance(config.learning_rate, float)
        
        print(f"âœ“ é…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"âœ“ è¾“å…¥ç»´åº¦: {config.input_dim}")
        print(f"âœ“ éšè—å±‚ç»´åº¦: {config.hidden_dims}")
        print(f"âœ“ åµŒå…¥ç»´åº¦: {config.embedding_dim}")
        print(f"âœ“ èšç±»æ•°: {config.num_clusters}")

def run_basic_functionality_test():
    """è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•"""
    print("="*80)
    print("Orchestra åŸºæœ¬åŠŸèƒ½æµ‹è¯•")
    print("="*80)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import torch
        import numpy as np
        import sklearn
        print(f"âœ“ PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ“ NumPyç‰ˆæœ¬: {np.__version__}")
        print(f"âœ“ Scikit-learnç‰ˆæœ¬: {sklearn.__version__}")
    except ImportError as e:
        print(f"âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥: {e}")
        return False
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        print(f"âœ“ CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
    else:
        print("âš  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    
    # è¿è¡Œå•å…ƒæµ‹è¯•
    print("\nå¼€å§‹å•å…ƒæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = loader.loadTestsFromTestCase(TestOrchestraComponents)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*80)
    print("æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*80)
    print(f"è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print("\nå¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback}")
    
    if result.errors:
        print("\né”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback}")
    
    success = len(result.failures) == 0 and len(result.errors) == 0
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Orchestraå®ç°åŸºæœ¬åŠŸèƒ½æ­£å¸¸ã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
    
    return success

def run_integration_test():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("\n" + "="*80)
    print("Orchestra é›†æˆæµ‹è¯•")
    print("="*80)
    
    try:
        # åˆ›å»ºå°è§„æ¨¡æµ‹è¯•æ•°æ®
        print("åˆ›å»ºæµ‹è¯•æ•°æ®...")
        num_samples = 200
        input_dim = 50
        num_clusters = 5
        
        data = np.random.randn(num_samples, input_dim)
        labels = np.random.randint(0, num_clusters, num_samples)
        
        # åˆ›å»ºé…ç½®
        config = OrchestraConfig(
            input_dim=input_dim,
            hidden_dims=[128, 64],
            embedding_dim=32,
            num_clusters=num_clusters,
            num_epochs=5,  # å°‘é‡è½®æ•°ç”¨äºæµ‹è¯•
            batch_size=32
        )
        
        # åˆ›å»ºæ¨¡å‹
        print("åˆ›å»ºæ¨¡å‹...")
        model = OrchestraModel(
            input_dim=config.input_dim,
            hidden_dims=config.hidden_dims,
            embedding_dim=config.embedding_dim,
            num_clusters=config.num_clusters
        )
        
        # åˆ›å»ºæŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        loss_fn = OrchestraLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        device = torch.device('cpu')
        trainer = OrchestraTrainer(model, loss_fn, optimizer, device)
        
        # ç®€å•è®­ç»ƒå¾ªç¯
        print("å¼€å§‹è®­ç»ƒ...")
        data_tensor = torch.tensor(data, dtype=torch.float32)
        labels_tensor = torch.tensor(labels, dtype=torch.long)
        
        for epoch in range(config.num_epochs):
            # åˆ†å‰²æ•°æ®æ¨¡æ‹Ÿå¤šä¸ªå®¢æˆ·ç«¯
            mid = len(data_tensor) // 2
            data_batches = [data_tensor[:mid], data_tensor[mid:]]
            
            losses = trainer.train_step(data_batches)
            
            if epoch % 2 == 0:
                print(f"Epoch {epoch}: Loss = {losses['total']:.4f}")
        
        # è¯„ä¼°
        print("è¯„ä¼°æ¨¡å‹...")
        eval_results = trainer.evaluate(data_tensor, labels_tensor)
        
        print("è¯„ä¼°ç»“æœ:")
        for key, value in eval_results.items():
            if isinstance(value, (int, float)):
                print(f"  {key}: {value:.4f}")
        
        print("\nğŸ‰ é›†æˆæµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("Orchestra å®ç°æµ‹è¯•")
    print("è¿™ä¸ªè„šæœ¬å°†æµ‹è¯•Orchestraå®ç°çš„å„ä¸ªç»„ä»¶")
    
    # è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•
    basic_success = run_basic_functionality_test()
    
    # è¿è¡Œé›†æˆæµ‹è¯•
    integration_success = run_integration_test()
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("æœ€ç»ˆæµ‹è¯•ç»“æœ")
    print("="*80)
    print(f"åŸºæœ¬åŠŸèƒ½æµ‹è¯•: {'âœ“ é€šè¿‡' if basic_success else 'âŒ å¤±è´¥'}")
    print(f"é›†æˆæµ‹è¯•: {'âœ“ é€šè¿‡' if integration_success else 'âŒ å¤±è´¥'}")
    
    if basic_success and integration_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Orchestraå®ç°å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        print("\nä¸‹ä¸€æ­¥å¯ä»¥è¿è¡Œ:")
        print("  python run_experiments.py --datasets cifar10 --num-epochs 10")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°æˆ–ä¾èµ–ã€‚")
        sys.exit(1)